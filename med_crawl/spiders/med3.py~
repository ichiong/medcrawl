from scrapy.contrib.spiders import CrawlSpider, Rule
from scrapy.contrib.linkextractors.sgml import SgmlLinkExtractor
from scrapy.selector import HtmlXPathSelector, Selector
from scrapy.utils.response import get_base_url
from med_crawl.items import MedCrawlItem

class MySpider(CrawlSpider):
    name = 'mcr3'
    allowed_domains = ['321.portal.athenahealth.com']
    start_urls = ['https://321.portal.athenahealth.com/']

    rules = (
        Rule(SgmlLinkExtractor(allow=('\/en\/item\-[a-z0-9\-]+\-scrap\.html')), process_links='process_links', callback='parse_item', follow=True),
        Rule(SgmlLinkExtractor(allow=('')), process_links='process_links', follow=True),
    )

    
    def parse(self, response):
        hxs = HtmlXPathSelector(response)
        #sel = Selector(response)
        sites = hxs.select("//div[@id='loginpane']")
        items = []
        
        
        for site in sites:
            item = MedCrawlItem()
            item['title'] = hxs.select('//form[contains(@id, "email")]').extract()
            #item['link'] = site.xpath('//div[contains(@class, "login")]').extract()
            item['link'] = get_base_url(response)
            items.append(item)
        return items
